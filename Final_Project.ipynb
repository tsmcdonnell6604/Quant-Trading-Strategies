{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINM 33150 Project Draft - Trading Volatility based on VIX Forecasts\n",
    "\n",
    "Sean Lin (12375235) | Thomas McDonnell (12365628) | Ben Panovich (12365148) | Madison Rusch (12365298)\n",
    "\n",
    "***\n",
    "\n",
    "## 1 Introduction\n",
    "\n",
    "In this notebook, we show the premise of what will become our quantitative trading strategy. As a quick summary, our trading strategy will involve capitalizing on volatility through the prediction of VIX. We will capitalize on this volatility by trading equity index options with a delta-hedged position in hopes to mitigate risk market directional risk. In addition, we will also trade other assets that move with volatility, notably futures, currencies, and bonds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import functools \n",
    "import itertools\n",
    "import quandl \n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = os.getenv('QUANDL_KEY')\n",
    "quandl.ApiConfig.api_key = KEY # Insert your key here if you want to run the code yourself "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data\n",
    "\n",
    "For data, we'll be using a variety of data sources. More specifically, the majority of our price data will come from Quandl with historical options pricing data coming from Polygon. It's important to note that VIX price data isn't on Quandl and as a result, we obtained historical VIX data through CBOE's website. For prediction of VIX, we utilized the economic calendar, with data retrieved from [fxstreet.com](https://www.fxstreet.com/economic-calendar) and the Shanghai index, with data obtained from [investing.com](https://www.investing.com/indices/shanghai-composite). For some analysis, we also retrieved historical implied volatilities through the VOL Quandl database (though you may not have access if you haven't purchased the dataset). All the raw data is included with this notebook.\n",
    "\n",
    "***\n",
    "\n",
    "**2.1 Helper Functions**\n",
    "\n",
    "We first define helper functions `fetch_quandl` and `fetch_quandl_table` to retrieve data from Quandl databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add documentation for function\n",
    "@functools.lru_cache()\n",
    "def fetch_quandl(asset, begin_date = None, end_date = None):\n",
    "    '''\n",
    "    Description\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    Returns:\n",
    "    '''\n",
    "    qdata = quandl.get(asset,\n",
    "                      start_date = begin_date,\n",
    "                      end_date = end_date,\n",
    "                      paginate=True)\n",
    "    return qdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add documentation for function\n",
    "@functools.lru_cache()\n",
    "def fetch_quandl_table(table, ticker, begin_date = None, end_date = None):\n",
    "    '''\n",
    "    Description\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    Returns:\n",
    "    '''\n",
    "    qdata = quandl.get_table(table,\n",
    "                      date = { 'gte': begin_date, 'lte': end_date },\n",
    "                      qopts = {\"columns\":[\"date\", \"adj_close\", \"adj_volume\"]},\n",
    "                      ticker = ticker,\n",
    "                      paginate=True)\n",
    "    qdata = qdata.set_index('date').sort_index(ascending=True)\n",
    "    return qdata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**2.1 Importing Model Data**\n",
    "\n",
    "Here, we will import the data needed for our predictions and analysis for our time period. We will first collect the data needed for predicting VIX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '2014-01-01'\n",
    "END_DATE = '2022-12-23'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first collect VIX data. This was taken from CBOE's website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/vix_data.csv'\n",
    "vix_data = pd.read_csv(filename)\n",
    "vix_data['DATE'] = pd.to_datetime(vix_data['DATE'])\n",
    "vix_data = vix_data.set_index('DATE')[['CLOSE']]\n",
    "vix_data = vix_data.loc[START_DATE:END_DATE]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now collect the economic calendar data. We obtain all the events considered *high importance* from FXStreet. In general, this consists of events like FOMC, CPI, Fed Chair Speeches, and Non-Farm Payroll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/economic_calendar.csv'\n",
    "event_data = pd.read_csv(filename)\n",
    "event_data['DATE'] = pd.to_datetime(event_data['Start']).dt.date\n",
    "event_data = event_data.set_index('DATE')\n",
    "\n",
    "# Obtain more economic calendar data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When considering days until an event, we want to consider the weekends as options pricing uses a full calendar year, not trading years (i.e theta decay applies over weekends). Thus, we want to calculate the time until an event (including weekends)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = vix_data.index\n",
    "all_dates = pd.date_range(START_DATE,END_DATE)\n",
    "\n",
    "temp = vix_data.copy()\n",
    "temp.columns = ['VIX']\n",
    "temp = temp.reindex(idx, fill_value=None)\n",
    "temp['Event'] = np.where(temp.index.isin(event_data.index.values), True, False)\n",
    "temp['Days until Event'] = np.where(temp['Event'] == True, 0, vix_data.groupby((temp['Event'] == True).cumsum()).cumcount(ascending=False)+1)\n",
    "temp = temp.dropna(subset=['VIX'])\n",
    "temp = temp[['VIX', 'Days until Event']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now obtain SPY data. We only want to consider US trading days. In other words, we only want to look at dates where SPY has a close (even if it's an early close)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_data = fetch_quandl_table('QUOTEMEDIA/PRICES','SPY',begin_date=START_DATE,end_date=END_DATE)\n",
    "spy_data.columns = ['SPY', 'SPY Volume']\n",
    "trading_days = spy_data.index \n",
    "temp = temp.loc[temp.index.isin(trading_days)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now import the Shanghai index data. This is used as the Shanghai Stock Exchange closes before the US Stock Exchange opens. This could potentially give us valuable information on the behavior of VIX during the next day as the global markets usually have some type of correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/ssec_data.csv'\n",
    "ssec_data = pd.read_csv(filename)\n",
    "ssec_data['Date'] = pd.to_datetime(ssec_data['Date'])\n",
    "ssec_data = ssec_data.set_index('Date')\n",
    "ssec_data = ssec_data.loc[ssec_data.index.isin(trading_days)].sort_index(ascending=True)\n",
    "ssec_data = ssec_data[['Price']].rename(columns={'Price':'SSEC'})\n",
    "ssec_data = ssec_data['SSEC'].str.replace(',','').astype(float).to_frame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now import Crude Oil futures data (CL). Since futures have quarterly expires, we will roll these over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:08<00:00,  4.18it/s]\n"
     ]
    }
   ],
   "source": [
    "securities = ['OWF/NYM_CL_CL']\n",
    "dates = ['H2014', 'M2014', 'U2014', 'Z2014',\n",
    "         'H2015', 'M2015', 'U2015', 'Z2015',\n",
    "         'H2016', 'M2016', 'U2016', 'Z2016',\n",
    "         'H2017', 'M2017', 'U2017', 'Z2017',\n",
    "         'H2018', 'M2018', 'U2018', 'Z2018',\n",
    "         'H2019', 'M2019', 'U2019', 'Z2019',\n",
    "         'H2020', 'M2020', 'U2020', 'Z2020',\n",
    "         'H2021', 'M2021', 'U2021', 'Z2021', \n",
    "         'H2022', 'M2022', 'U2022', 'Z2022',\n",
    "         'H2023']\n",
    "\n",
    "# Fetch NYM_RB_RB Data\n",
    "finalized_data = pd.DataFrame()\n",
    "security = securities[0]\n",
    "trim_start = START_DATE\n",
    "trim_end = END_DATE\n",
    "for month in tqdm(dates):\n",
    "  data = fetch_quandl(f'{security}_{month}_IVM', begin_date=trim_start, end_date=trim_end)\n",
    "  # data = clean_quandl_columns(data)\n",
    "  # data = data[data['DtT'] > 30]\n",
    "  if finalized_data.empty:\n",
    "    finalized_data = data\n",
    "  else:\n",
    "    finalized_data = pd.concat([finalized_data, data])\n",
    "  trim_start = finalized_data.index[-1] + pd.DateOffset(1)\n",
    "\n",
    "cl_data = finalized_data.copy()[['Future']].rename(columns={'Future':'CL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([temp, spy_data, ssec_data, cl_data], axis=1)\n",
    "\n",
    "all_data['VIX Returns'] = all_data['VIX'].pct_change()\n",
    "all_data['SPY Returns'] = all_data['SPY'].pct_change()\n",
    "all_data['SSEC Returns'] = all_data['SSEC'].pct_change()\n",
    "all_data['CL Returns'] = all_data['CL'].pct_change()\n",
    "\n",
    "predictors = all_data[['Days until Event','SPY Volume','VIX Returns','SPY Returns','SSEC Returns','CL Returns']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors['VIX Returns (y)'] = predictors['VIX Returns'].shift(-1)\n",
    "predictors['SSEC Returns'] = predictors['SSEC Returns'].shift(-1)\n",
    "predictors = predictors.drop(columns=['VIX Returns'])\n",
    "\n",
    "predictors = predictors.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# 3 Predicting VIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TRAIN = '2014-01-03'\n",
    "END_TRAIN = '2014-06-03'\n",
    "\n",
    "START_TEST = END_TRAIN \n",
    "END_TEST = '2020-12-31'\n",
    "\n",
    "START_VAL = END_TEST \n",
    "END_VAL = '2022-12-22'\n",
    "\n",
    "ROLLING = True\n",
    "\n",
    "arima_data = predictors.loc[START_TRAIN:END_TEST]\n",
    "\n",
    "last_train = arima_data.loc[:END_TRAIN].index[-1]\n",
    "end_train_loc = arima_data.index.get_loc(last_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(p,d,q,thresh_up,thresh_down):\n",
    "    metrics = pd.DataFrame(index=[str((p,d,q))],columns=['MSE','DA','Up Acc','Down Acc','Tot Significant'])\n",
    "    predicted_results = pd.DataFrame(index = predictors.loc[START_TEST:END_TEST].index,columns=['predictions'])\n",
    "    start, end = 0, end_train_loc \n",
    "    for i in range(len(arima_data.loc[START_TEST:END_TEST])):\n",
    "        model = ARIMA(arima_data.iloc[start:end]['VIX Returns (y)'], order=(p,d,q), exog=arima_data.iloc[start:end,:5]).fit()\n",
    "        forecast = model.forecast(1, exog=arima_data.iloc[end,:5])\n",
    "\n",
    "        if ROLLING == True:\n",
    "            start = start + 1 \n",
    "        end = end + 1 \n",
    "\n",
    "        predicted_results.iloc[i] = forecast\n",
    "\n",
    "    predicted_results = predicted_results.dropna()\n",
    "    predicted_results['actual'] = arima_data.loc[START_TEST:END_TEST,'VIX Returns (y)']\n",
    "\n",
    "    mse = np.mean((predicted_results['actual'] - predicted_results['predictions']) ** 2)\n",
    "    da = (np.sign(predicted_results['predictions']) == np.sign(predicted_results['actual'])).sum() / len(predicted_results)\n",
    "\n",
    "    significant_up = predicted_results[predicted_results['predictions'] > thresh_up]\n",
    "    acc_up = (np.sign(significant_up['predictions']) == np.sign(significant_up['actual'])).sum() / len(significant_up)\n",
    "    significant_down = predicted_results[predicted_results['predictions'] < thresh_down]\n",
    "    acc_down = (np.sign(significant_down['predictions']) == np.sign(significant_down['actual'])).sum() / len(significant_down)\n",
    "    total_sig = len(significant_up) + len(significant_down)\n",
    "\n",
    "    metrics.loc[str((p,d,q))] = [mse,da,acc_up,acc_down,total_sig]\n",
    "    return metrics, predicted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'p': range(0,5),\n",
    "    'd': range(0,3),\n",
    "    'q': range(0,5)\n",
    "}\n",
    "\n",
    "param_combinations = list(itertools.product(*(param_grid[param] for param in param_grid)))\n",
    "\n",
    "def optimize(params):\n",
    "    p, d, q = params\n",
    "    metric = test_model(p,d,q,0.07,-0.07)\n",
    "    return metric "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize our ARIMA parameters, we will use an initial training period of 6m (2014-01 - 2014-06). We will use a rolling window to forecast predictions until the end of 2020. We will then determine our best model based on this period. After selecting the best model, we will use this to test out-of-sample on our validation period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_OPTIMIZATION = False \n",
    "\n",
    "if RUN_OPTIMIZATION:\n",
    "    optimization_res = pd.DataFrame(columns=['MSE','DA','Up Acc','Down Acc','Tot Significant'])\n",
    "    for combo in tqdm(param_combinations):\n",
    "        p, d, q = combo \n",
    "        metric = test_model(p,d,q,0.07,-0.07)\n",
    "        optimization_res.loc[str((p,d,q))] = metric.values[0]\n",
    "else:\n",
    "    optimization_res = pd.read_csv('./data/optimization_stats.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>DA</th>\n",
       "      <th>Up Acc</th>\n",
       "      <th>Down Acc</th>\n",
       "      <th>Tot Significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0, 0, 1)</th>\n",
       "      <td>0.009271</td>\n",
       "      <td>0.514768</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(4, 1, 4)</th>\n",
       "      <td>0.014459</td>\n",
       "      <td>0.512960</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(3, 2, 4)</th>\n",
       "      <td>0.027534</td>\n",
       "      <td>0.512357</td>\n",
       "      <td>0.448622</td>\n",
       "      <td>0.557841</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 1, 0)</th>\n",
       "      <td>0.014551</td>\n",
       "      <td>0.510549</td>\n",
       "      <td>0.448889</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, 0, 0)</th>\n",
       "      <td>0.009306</td>\n",
       "      <td>0.510549</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MSE        DA    Up Acc  Down Acc  Tot Significant\n",
       "(0, 0, 1)  0.009271  0.514768  0.500000  0.821429               70\n",
       "(4, 1, 4)  0.014459  0.512960  0.448276  0.544118              310\n",
       "(3, 2, 4)  0.027534  0.512357  0.448622  0.557841              788\n",
       "(0, 1, 0)  0.014551  0.510549  0.448889  0.534483              399\n",
       "(1, 0, 0)  0.009306  0.510549  0.512195  0.785714               69"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_res.sort_values(by='DA',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>DA</th>\n",
       "      <th>Up Acc</th>\n",
       "      <th>Down Acc</th>\n",
       "      <th>Tot Significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(4, 0, 3)</th>\n",
       "      <td>0.010521</td>\n",
       "      <td>0.490054</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, 0, 0)</th>\n",
       "      <td>0.009306</td>\n",
       "      <td>0.510549</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, 0, 1)</th>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.510549</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2, 0, 2)</th>\n",
       "      <td>0.010837</td>\n",
       "      <td>0.506329</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(4, 0, 4)</th>\n",
       "      <td>0.011393</td>\n",
       "      <td>0.486438</td>\n",
       "      <td>0.506024</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MSE        DA    Up Acc  Down Acc  Tot Significant\n",
       "(4, 0, 3)  0.010521  0.490054  0.535714  0.625000              112\n",
       "(1, 0, 0)  0.009306  0.510549  0.512195  0.785714               69\n",
       "(1, 0, 1)  0.009675  0.510549  0.510204  0.766667               79\n",
       "(2, 0, 2)  0.010837  0.506329  0.507463  0.693878              116\n",
       "(4, 0, 4)  0.011393  0.486438  0.506024  0.688525              144"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_res.sort_values(by='Up Acc',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>DA</th>\n",
       "      <th>Up Acc</th>\n",
       "      <th>Down Acc</th>\n",
       "      <th>Tot Significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0, 0, 1)</th>\n",
       "      <td>0.009271</td>\n",
       "      <td>0.514768</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0, 0, 0)</th>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.504521</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, 0, 0)</th>\n",
       "      <td>0.009306</td>\n",
       "      <td>0.510549</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2, 0, 0)</th>\n",
       "      <td>0.009378</td>\n",
       "      <td>0.499096</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, 0, 1)</th>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.510549</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MSE        DA    Up Acc  Down Acc  Tot Significant\n",
       "(0, 0, 1)  0.009271  0.514768  0.500000  0.821429               70\n",
       "(0, 0, 0)  0.009181  0.504521  0.461538  0.814815               66\n",
       "(1, 0, 0)  0.009306  0.510549  0.512195  0.785714               69\n",
       "(2, 0, 0)  0.009378  0.499096  0.431818  0.777778               80\n",
       "(1, 0, 1)  0.009675  0.510549  0.510204  0.766667               79"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_res.sort_values(by='Down Acc',ascending=False).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best ones:\n",
    "- (0,0,1) looks to be most robust one (highest directional accuracy for a simple TS model)\n",
    "\n",
    "**Testing out of sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2157/2157 [02:48<00:00, 12.78it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_data = predictors.loc[START_TRAIN:END_VAL]\n",
    "p, d, q = 1, 1, 1\n",
    "\n",
    "last_test= validation_data.loc[:END_TRAIN].index[-1]\n",
    "end_test_loc = validation_data.index.get_loc(last_test)\n",
    "\n",
    "metrics = pd.DataFrame(columns=['MSE','DA','Up Acc','Down Acc','Tot Significant'])\n",
    "predicted_results = pd.DataFrame(index = predictors.loc[START_TEST:END_VAL].index,columns=['predictions'])\n",
    "start, end = 0, end_test_loc \n",
    "for i in tqdm(range(len(validation_data.loc[START_TEST:END_VAL]))):\n",
    "    model = ARIMA(validation_data.iloc[start:end]['VIX Returns (y)'], order=(p,d,q), exog=validation_data.iloc[start:end,:5]).fit()\n",
    "    forecast = model.forecast(1, exog=validation_data.iloc[end,:5])\n",
    "\n",
    "    if ROLLING == True:\n",
    "        start = start + 1 \n",
    "    end = end + 1 \n",
    "\n",
    "    predicted_results.iloc[i] = forecast\n",
    "\n",
    "predicted_results = predicted_results.dropna()\n",
    "predicted_results['actual'] = validation_data.loc[START_TEST:END_VAL,'VIX Returns (y)']\n",
    "predicted_results_val = predicted_results.loc[START_VAL:END_VAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_results_val = predicted_results.loc[START_VAL:END_VAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>DA</th>\n",
       "      <th>Up Acc</th>\n",
       "      <th>Down Acc</th>\n",
       "      <th>Tot Significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(1, 1, 1)</th>\n",
       "      <td>0.014568</td>\n",
       "      <td>0.48497</td>\n",
       "      <td>0.41791</td>\n",
       "      <td>0.54</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MSE       DA   Up Acc  Down Acc  Tot Significant\n",
       "(1, 1, 1)  0.014568  0.48497  0.41791      0.54            117.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_thres = 0.07\n",
    "neg_thres = -0.07\n",
    "\n",
    "mse = np.mean((predicted_results_val['actual'] - predicted_results_val['predictions']) ** 2)\n",
    "da = (np.sign(predicted_results_val['predictions']) == np.sign(predicted_results_val['actual'])).sum() / len(predicted_results_val)\n",
    "\n",
    "significant_up = predicted_results_val[predicted_results_val['predictions'] > pos_thres]\n",
    "acc_up = (np.sign(significant_up['predictions']) == np.sign(significant_up['actual'])).sum() / len(significant_up)\n",
    "significant_down = predicted_results_val[predicted_results_val['predictions'] < neg_thres]\n",
    "acc_down = (np.sign(significant_down['predictions']) == np.sign(significant_down['actual'])).sum() / len(significant_down)\n",
    "total_sig = len(significant_up) + len(significant_down)\n",
    "\n",
    "metrics.loc[str((p,d,q))] = [mse,da,acc_up,acc_down,total_sig]\n",
    "display(metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPY Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache()\n",
    "def fetch_options_price(option,date):\n",
    "    data_url = f'https://api.polygon.io/v1/open-close/{option}/{date}?adjusted=true&apiKey=cIrLrp5MiBJNGpjRm4hv7hoSbNVirkxx'\n",
    "    # data_url = f'https://api.polygon.io/v3/snapshot/options/{ticker}?apiKey=cIrLrp5MiBJNGpjRm4hv7hoSbNVirkxx'\n",
    "    # data_url = data_url + f'&expiration_data.gte={begin_date}'\n",
    "    # data_url = data_url + f'&expiration_data.lte={end_date}'\n",
    "    response = requests.get(data_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_options(date):\n",
    "    dates = spy_data.loc[date:].index[:20]\n",
    "    atm_put_strike = math.ceil(spy_data.loc[dates[0],'SPY'])\n",
    "    atm_call_strike = math.floor(spy_data.loc[dates[0],'SPY'])\n",
    "    \n",
    "    i = -10 \n",
    "    call = 404 \n",
    "    while call == 404:\n",
    "        last_date = dates[i].strftime('%y%m%d')\n",
    "        call_code = 'O:SPY' + last_date + 'C' + '00' + str(atm_call_strike) + '000'\n",
    "        put_code = 'O:SPY' + last_date + 'P' + '00' + str(atm_put_strike) + '000'\n",
    "        call = fetch_options_price(call_code, date)\n",
    "        i = i + 1 \n",
    "\n",
    "    last_date = datetime.datetime.strptime(last_date,'%y%m%d')\n",
    "    last_date = last_date.strftime('%Y-%m-%d')\n",
    "    valid_dates = spy_data.loc[dates[0]:last_date].index\n",
    "\n",
    "    option_prices = pd.DataFrame(index=valid_dates,columns=[call_code,put_code,'SPY'])\n",
    "    for day in option_prices.index:\n",
    "        call_res = fetch_options_price(call_code, day.strftime('%Y-%m-%d'))\n",
    "        put_res = fetch_options_price(put_code, day.strftime('%Y-%m-%d'))\n",
    "\n",
    "        if not isinstance(call_res, int):\n",
    "            option_prices.loc[day,call_code] = call_res['close']\n",
    "\n",
    "        if not isinstance(put_res, int):\n",
    "            option_prices.loc[day,put_code] = put_res['close']\n",
    "\n",
    "    option_prices['SPY'] = spy_data.loc[dates[0]:last_date,'SPY']\n",
    "\n",
    "    return option_prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O:SPY220309C00415000</th>\n",
       "      <th>O:SPY220309P00416000</th>\n",
       "      <th>SPY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-02-23</th>\n",
       "      <td>14.88</td>\n",
       "      <td>6.89</td>\n",
       "      <td>415.196034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-24</th>\n",
       "      <td>16.69</td>\n",
       "      <td>4.32</td>\n",
       "      <td>421.444392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-25</th>\n",
       "      <td>24.46</td>\n",
       "      <td>2.16</td>\n",
       "      <td>430.743130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-28</th>\n",
       "      <td>23.81</td>\n",
       "      <td>3.2</td>\n",
       "      <td>429.641057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-01</th>\n",
       "      <td>18.49</td>\n",
       "      <td>3.71</td>\n",
       "      <td>423.097501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-02</th>\n",
       "      <td>21.12</td>\n",
       "      <td>1.49</td>\n",
       "      <td>430.880889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-03</th>\n",
       "      <td>24.41</td>\n",
       "      <td>1.45</td>\n",
       "      <td>428.735783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-04</th>\n",
       "      <td>17.5</td>\n",
       "      <td>1.37</td>\n",
       "      <td>425.252447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-07</th>\n",
       "      <td>7.04</td>\n",
       "      <td>3.67</td>\n",
       "      <td>412.716370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-08</th>\n",
       "      <td>3.51</td>\n",
       "      <td>3.42</td>\n",
       "      <td>409.587271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-09</th>\n",
       "      <td>11.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>420.568638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           O:SPY220309C00415000 O:SPY220309P00416000         SPY\n",
       "date                                                            \n",
       "2022-02-23                14.88                 6.89  415.196034\n",
       "2022-02-24                16.69                 4.32  421.444392\n",
       "2022-02-25                24.46                 2.16  430.743130\n",
       "2022-02-28                23.81                  3.2  429.641057\n",
       "2022-03-01                18.49                 3.71  423.097501\n",
       "2022-03-02                21.12                 1.49  430.880889\n",
       "2022-03-03                24.41                 1.45  428.735783\n",
       "2022-03-04                 17.5                 1.37  425.252447\n",
       "2022-03-07                 7.04                 3.67  412.716370\n",
       "2022-03-08                 3.51                 3.42  409.587271\n",
       "2022-03-09                 11.9                 0.01  420.568638"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_options('2022-02-23') # russian invasion "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant-trading-strats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f007e1c0381c2fbbfc96ad3b33b0ae4e0644077dc3163f31c2a03343da974ece"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
